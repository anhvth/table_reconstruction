{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_bounding/049.png\n",
      "data/train_bounding/000.png\n",
      "data/train_bounding/132.png\n",
      "data/train_bounding/017.png\n",
      "data/train_bounding/023.png\n",
      "data/train_bounding/031.png\n",
      "data/train_bounding/127.png\n",
      "data/train_bounding/030.png\n",
      "data/train_bounding/037.png\n",
      "data/train_bounding/015.png\n",
      "data/train_bounding/022.png\n",
      "data/train_bounding/028.png\n",
      "data/train_bounding/038.png\n",
      "data/train_bounding/010.png\n",
      "data/train_bounding/041.png\n",
      "data/train_bounding/014.png\n",
      "data/train_bounding/018.png\n",
      "data/train_bounding/032.png\n",
      "data/train_bounding/051.png\n",
      "data/train_bounding/008.png\n",
      "data/train_bounding/130.png\n",
      "data/train_bounding/126.png\n",
      "data/train_bounding/043.png\n",
      "data/train_bounding/034.png\n",
      "data/train_bounding/024.png\n",
      "data/train_bounding/019.png\n",
      "data/train_bounding/096.png\n",
      "data/train_bounding/003.png\n",
      "data/train_bounding/001.png\n",
      "data/train_bounding/128.png\n",
      "data/train_bounding/046.png\n",
      "data/train_bounding/012.png\n",
      "data/train_bounding/134.png\n",
      "data/train_bounding/045.png\n",
      "data/train_bounding/029.png\n",
      "data/train_bounding/025.png\n",
      "data/train_bounding/131.png\n",
      "data/train_bounding/040.png\n",
      "data/train_bounding/044.png\n",
      "data/train_bounding/144.png\n",
      "data/train_bounding/050.png\n",
      "data/train_bounding/047.png\n",
      "data/train_bounding/013.png\n",
      "data/train_bounding/009.png\n",
      "data/train_bounding/033.png\n",
      "data/train_bounding/133.png\n",
      "data/train_bounding/011.png\n",
      "data/train_bounding/026.png\n",
      "data/train_bounding/006.png\n",
      "data/train_bounding/129.png\n",
      "data/train_bounding/016.png\n",
      "data/train_bounding/042.png\n",
      "data/train_bounding/004.png\n",
      "data/train_bounding/053.png\n",
      "data/train_bounding/007.png\n",
      "data/train_bounding/039.png\n",
      "data/train_bounding/027.png\n",
      "data/train_bounding/052.png\n",
      "data/train_bounding/002.png\n",
      "data/train_bounding/097.png\n",
      "data/train_bounding/020.png\n",
      "data/train_bounding/048.png\n",
      "data/train_bounding/021.png\n",
      "data/train_bounding/005.png\n"
     ]
    }
   ],
   "source": [
    "!python tools/create_train_data_from_label_xml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Counting objects: 4, done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (4/4), done.\n",
      "From https://github.com/vnbot2/thesis\n",
      "   d0ecbcb..bde2657  master     -> origin/master\n",
      "Updating d0ecbcb..bde2657\n",
      "Fast-forward\n",
      " tools/create_data.py | 3 \u001b[32m+\u001b[m\u001b[31m--\u001b[m\n",
      " 1 file changed, 1 insertion(+), 2 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of inputs:  64\n",
      "data/train_bounding/049.png\n",
      "data/train_bounding/000.png\n",
      "data/train_bounding/132.png\n",
      "data/train_bounding/017.png\n",
      "data/train_bounding/023.png\n",
      "data/train_bounding/031.png\n",
      "data/train_bounding/127.png\n",
      "data/train_bounding/030.png\n",
      "data/train_bounding/037.png\n",
      "data/train_bounding/015.png\n",
      "data/train_bounding/022.png\n",
      "data/train_bounding/028.png\n",
      "data/train_bounding/038.png\n",
      "data/train_bounding/010.png\n",
      "data/train_bounding/041.png\n",
      "data/train_bounding/014.png\n",
      "data/train_bounding/018.png\n",
      "data/train_bounding/032.png\n",
      "data/train_bounding/051.png\n",
      "data/train_bounding/008.png\n",
      "data/train_bounding/130.png\n",
      "data/train_bounding/126.png\n",
      "data/train_bounding/043.png\n",
      "data/train_bounding/034.png\n",
      "data/train_bounding/024.png\n",
      "data/train_bounding/019.png\n",
      "data/train_bounding/096.png\n",
      "data/train_bounding/003.png\n",
      "data/train_bounding/001.png\n",
      "data/train_bounding/128.png\n",
      "data/train_bounding/046.png\n",
      "data/train_bounding/012.png\n",
      "data/train_bounding/134.png\n",
      "data/train_bounding/045.png\n",
      "data/train_bounding/029.png\n",
      "data/train_bounding/025.png\n",
      "data/train_bounding/131.png\n",
      "data/train_bounding/040.png\n",
      "data/train_bounding/044.png\n",
      "data/train_bounding/144.png\n",
      "data/train_bounding/050.png\n",
      "data/train_bounding/047.png\n",
      "data/train_bounding/013.png\n",
      "data/train_bounding/009.png\n",
      "data/train_bounding/033.png\n",
      "data/train_bounding/133.png\n",
      "data/train_bounding/011.png\n",
      "data/train_bounding/026.png\n",
      "data/train_bounding/006.png\n",
      "data/train_bounding/129.png\n",
      "data/train_bounding/016.png\n",
      "data/train_bounding/042.png\n",
      "data/train_bounding/004.png\n",
      "data/train_bounding/053.png\n",
      "data/train_bounding/007.png\n",
      "data/train_bounding/039.png\n",
      "data/train_bounding/027.png\n",
      "data/train_bounding/052.png\n",
      "data/train_bounding/002.png\n",
      "data/train_bounding/097.png\n",
      "data/train_bounding/020.png\n",
      "data/train_bounding/048.png\n",
      "data/train_bounding/021.png\n",
      "data/train_bounding/005.png\n"
     ]
    }
   ],
   "source": [
    "!python tools/create_data.py --n_sample 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "len(glob('data/synthetic_data_bounding/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX\t\t text_line_verified\t train_bounding\r\n",
      "synthetic_data_bounding  text_line_verified.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128x1024_64_data\r\n"
     ]
    }
   ],
   "source": [
    "! ls pix2pix/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded lab_colorization = False\n",
      "loaded ndf = 32\n",
      "loaded ngf = 32\n",
      "loaded which_direction = AtoB\n",
      "aspect_ratio = 1.0\n",
      "batch_size = 1\n",
      "beta1 = 0.5\n",
      "checkpoint = pix2pix/output/128x1024_64_data\n",
      "display_freq = 0\n",
      "flip = False\n",
      "gan_weight = 1.0\n",
      "input_dir = None\n",
      "l1_weight = 100.0\n",
      "lab_colorization = False\n",
      "lr = 0.0002\n",
      "max_epochs = None\n",
      "max_steps = None\n",
      "mode = export\n",
      "ndf = 32\n",
      "ngf = 32\n",
      "output_dir = pix2pix/frozen/128x1024\n",
      "output_filetype = png\n",
      "progress_freq = 50\n",
      "save_freq = 1000\n",
      "scale_size = [128, 1024]\n",
      "seed = 2139197480\n",
      "separable_conv = False\n",
      "summary_freq = 100\n",
      "trace_freq = 0\n",
      "which_direction = AtoB\n",
      "Batch input: Tensor(\"truediv:0\", shape=(?, 128, 1024, 3), dtype=float32)\n",
      "Create GENERATOR--------------------------------\n",
      "(?, 64, 512, 32)\n",
      "(?, 32, 256, 64)\n",
      "(?, 16, 128, 128)\n",
      "(?, 8, 64, 256)\n",
      "(?, 4, 32, 256)\n",
      "(?, 2, 16, 256)\n",
      "(?, 1, 8, 256)\n",
      "(?, 1, 4, 256)\n",
      "DECONV\n",
      "(?, 1, 8, 256)\n",
      "(?, 2, 16, 256)\n",
      "(?, 4, 32, 256)\n",
      "(?, 8, 64, 256)\n",
      "(?, 16, 128, 128)\n",
      "(?, 32, 256, 64)\n",
      "(?, 64, 512, 32)\n",
      "(?, 128, 1024, 3)\n",
      "image: Tensor(\"generator/decoder_1/Tanh:0\", shape=(?, 128, 1024, 3), dtype=float32)\n",
      "2018-03-31 00:24:24.162223: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2018-03-31 00:24:24.460429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2018-03-31 00:24:24.460794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.835\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 7.93GiB freeMemory: 7.42GiB\n",
      "2018-03-31 00:24:24.460813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "loading model from checkpoint\n",
      "exporting model: pix2pix/output/128x1024_64_data/model-150000\n"
     ]
    }
   ],
   "source": [
    "!bash script/pix2pix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
